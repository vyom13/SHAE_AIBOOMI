# ========================================
# BACKEND SELECTION
# ========================================
# Choose: "ollama" (local) or "hf_router" (HuggingFace)
BACKEND=ollama

# ========================================
# HUGGINGFACE ROUTER CONFIGURATION
# ========================================
# Only needed if BACKEND=hf_router
HF_TOKEN=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
HF_CHAT_MODEL=meta-llama/Llama-3.1-8B-Instruct:cerebras

# ========================================
# OLLAMA CONFIGURATION (Local LLM)
# ========================================
# Only needed if BACKEND=ollama
# Default Ollama URL (don't change unless using custom port)
OLLAMA_BASE_URL=http://localhost:11434/v1
# Model to use (run: ollama pull llama3.1:8b)
OLLAMA_MODEL=llama3.1:8b

# ========================================
# LLM PARAMETERS
# ========================================
MAX_NEW_TOKENS=512
TEMPERATURE=0.3
TOP_P=0.9
