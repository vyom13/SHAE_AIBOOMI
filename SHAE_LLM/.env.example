# Backend Configuration
BACKEND=ollama

# Ollama Configuration (for local LLM)
OLLAMA_BASE_URL=http://localhost:11434/v1
OLLAMA_MODEL=llama3.1:8b

# HuggingFace Router Configuration (alternative cloud-based option)
# BACKEND=hf_router
# ROUTER_BASE_URL=https://serverless-router.endpoints.huggingface.cloud/v1
# HF_TOKEN=your_huggingface_token_here
# HF_CHAT_MODEL=meta-llama/Llama-3.1-8B-Instruct:cerebras

# LLM Parameters
MAX_NEW_TOKENS=512
TEMPERATURE=0.3
TOP_P=0.9
